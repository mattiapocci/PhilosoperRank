{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "scrapingWikiDumps.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "gI8Q628Jwhu_",
        "kU4Kft8-GKvT"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiapocci/PhilosoperRank/blob/master/scrapingWikiDumps.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gI8Q628Jwhu_",
        "colab_type": "text"
      },
      "source": [
        "## Import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzk8gP9t-sU3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import json\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nwKVtmI_YQs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget  -P \"/content/drive/My Drive/Wiki_dump/\" \"https://dumps.wikimedia.org/enwiki/20200120/enwiki-20200120-pages-articles-multistream.xml.bz2\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6Ul1mbbukNF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!bunzip2 -d -k -s /content/drive/My\\ Drive/Wiki_dump/enwiki-20200120-pages-articles-multistream.xml.bz2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSeuNCsgY64U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!python3 WikiExtractor.py \"enwiki-20200120-pages-articles-multistream.xml\"  --json --processes 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1QRTdVPwskg",
        "colab_type": "text"
      },
      "source": [
        "## Parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kU4Kft8-GKvT",
        "colab_type": "text"
      },
      "source": [
        "### Parsing utility"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a5KljeSoo7M8",
        "colab_type": "code",
        "outputId": "d6f920e9-a7b4-44fe-bb32-ff0cfcf1cb78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def create_valid_json(filename):\n",
        "    \"\"\"\n",
        "    Create a valid json with the commas and the square brackets\n",
        "    :param string:\n",
        "    :return: None \n",
        "    \"\"\"\n",
        "    with open(filename, 'r+') as f:\n",
        "        data = f.read().replace('}', '},')\n",
        "        data = data[:-2]\n",
        "        f.seek(0, 0)\n",
        "        f.write('['.rstrip('\\r\\n') + '\\n' + data)\n",
        "        \n",
        "    with open(filename, 'a') as f:\n",
        "        f.write(\"]\")\n",
        "\n",
        "\n",
        "def find_matches(filename,word,phil_list):\n",
        "    \"\"\"\n",
        "    Find matches inside the articles with the given word and add it to the given phil_list\n",
        "    :param string:\n",
        "    :param string:\n",
        "    :param list:\n",
        "    :return: list of the articles containg the word philosopher\n",
        "    \"\"\"\n",
        "    #phil_list = []\n",
        "    with open(filename, 'r', encoding='utf-8') as file:\n",
        "        try:\n",
        "            data = json.loads(file.read())\n",
        "            for article in data:\n",
        "                if word in article['text']:\n",
        "                    phil_list.append(article)\n",
        "            return phil_list\n",
        "        except:\n",
        "            print(\"Error with: \", filename)\n",
        "\n",
        "\n",
        "def write_json(data, name):\n",
        "    \"\"\"\n",
        "    Write into a file the data given with the name given\n",
        "    :param lst of json:\n",
        "    :param string:\n",
        "    :return: None\n",
        "    \"\"\"\n",
        "    with open('/content/drive/My Drive/Wiki_dump/'+name, 'w') as outfile:\n",
        "        json.dump(data, outfile)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "26312\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZkURNTLFho4",
        "colab_type": "text"
      },
      "source": [
        "### Executing the parsing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ene_FPbdKO2f",
        "colab_type": "text"
      },
      "source": [
        "If the wikipedia articles are yet parsed with the create_valid_json function, do NOT redo the parsing, otherwise you will mess all the articles!!! To avoid this, comment the indicated line."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Gy9_qi6w25y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def parse_data(rootdir=\"/home/luigi/Downloads/wir/wikiextractor-master/text/\"):\n",
        "    \"\"\"\n",
        "    Parse all the files presents in the rootdir and its subdirectories\n",
        "    :param string:\n",
        "    :return: None \n",
        "    \"\"\"\n",
        "    lst = []\n",
        "    for subdir, dirs, files in os.walk(rootdir):\n",
        "        for file in files:\n",
        "            filename_fullpath = os.path.join(subdir, file)\n",
        "            create_valid_json(filename_fullpath) #THIS LINE TO BE COMMENTED according to what is written above\n",
        "            lst = find_matches(filename_fullpath,\"philosopher\",lst)\n",
        "    write_json(lst,file)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oY0JvqLuHGuW",
        "colab_type": "text"
      },
      "source": [
        "testing if we parsed well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Egd0XqaOHFK7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "with open(\"/content/drive/My Drive/Wiki_dump/wiki_75.json\", 'r', encoding='utf-8') as file:\n",
        "  data = json.loads(file.read())\n",
        "  print(len(data))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}