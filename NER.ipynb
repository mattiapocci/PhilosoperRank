{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SELDnet_g (1).ipynb",
      "provenance": [],
      "collapsed_sections": [
        "UXG6e2PquoqN",
        "W0EkabEj_ah5",
        "P3Lkxc3TGf2C",
        "VQ-X5gRG_lY3",
        "z1d5ODXo_0OU",
        "YgTsIgOHAmec",
        "-TlgXGWWF1Xa",
        "EazLeWiLEBST"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiapocci/PhilosoperRank/blob/master/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0EkabEj_ah5",
        "colab_type": "text"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcg7xL1K7yyZ",
        "colab_type": "code",
        "outputId": "22e39486-3065-44ae-b1e5-4f7038bd8c28",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 485
        }
      },
      "source": [
        "def collect_test_labels(_data_gen_test, _data_out, classification_mode, quick_test):\n",
        "    # Collecting ground truth for test data\n",
        "    nb_batch = 2 if quick_test else _data_gen_test.get_total_batches_in_data()\n",
        "\n",
        "    batch_size = _data_out[0][0]\n",
        "    gt_sed = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[0][2]))\n",
        "    gt_doa = np.zeros((nb_batch * batch_size, _data_out[0][1], _data_out[1][2]))\n",
        "\n",
        "    print(\"nb_batch in test: {}\".format(nb_batch))\n",
        "    cnt = 0\n",
        "    for tmp_feat, tmp_label in _data_gen_test.generate():\n",
        "        gt_sed[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[0]\n",
        "        gt_doa[cnt * batch_size:(cnt + 1) * batch_size, :, :] = tmp_label[1]\n",
        "        cnt = cnt + 1\n",
        "        if cnt == nb_batch:\n",
        "            break\n",
        "    return gt_sed.astype(int), gt_doa\n",
        "    \n",
        "def print_generic_evaluation(model, _dataset, _ov, _split):\n",
        "    data_gen_test = DataGenerator(\n",
        "            dataset=_dataset, ov=_ov, split=_split, db=params['db'], nfft=params['nfft'],\n",
        "            batch_size=params['batch_size'], seq_len=params['sequence_length'], classifier_mode=params['mode'],\n",
        "            weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "            azi_only=params['azi_only'], shuffle=False\n",
        "        )\n",
        "    \n",
        "    values = model.evaluate_generator(data_gen_test.generate(),\n",
        "                                steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "                                verbose = 1)\n",
        "    print(\"Accuracy and Loss evaluation for dataset\", _dataset,\n",
        "          \"ov\", _ov, \"split\", _split)\n",
        "    i = 0\n",
        "    for name in model.metrics_names:\n",
        "        print(name, values[i])\n",
        "        i+=1\n",
        "\n",
        "def print_sed_doa_scores(model, _dataset, _ov, _split):\n",
        "    data_gen_test = DataGenerator(\n",
        "            dataset=_dataset, ov=_ov, split=_split, db=params['db'], nfft=params['nfft'],\n",
        "            batch_size=params['batch_size'], seq_len=params['sequence_length'], classifier_mode=params['mode'],\n",
        "            weakness=params['weakness'], datagen_mode='test', cnn3d=params['cnn_3d'], xyz_def_zero=params['xyz_def_zero'],\n",
        "            azi_only=params['azi_only'], shuffle=False\n",
        "        )\n",
        "\n",
        "    gt = collect_test_labels(data_gen_test, data_out, params['mode'], params['quick_test'])\n",
        "    sed_gt = reshape_3Dto2D(gt[0])\n",
        "    doa_gt = reshape_3Dto2D(gt[1])\n",
        "\n",
        "    pred = model.predict_generator(\n",
        "                generator=data_gen_test_1.generate(),\n",
        "                steps=2 if params['quick_test'] else data_gen_test.get_total_batches_in_data(),\n",
        "                verbose=1\n",
        "            )\n",
        "\n",
        "    sed_pred = reshape_3Dto2D(pred[0]) > 0.5\n",
        "    doa_pred = reshape_3Dto2D(pred[1])\n",
        "\n",
        "    sed_scores = compute_sed_scores(sed_pred, sed_gt, data_gen_test.nb_frames_1s())\n",
        "    if params['azi_only']:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xy(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "    else:\n",
        "        doa_scores, conf_mat = compute_doa_scores_regr_xyz(doa_pred, doa_gt, sed_pred, sed_gt)\n",
        "        \n",
        "    #print('Confusion Mx : {}'.format(conf_mat))\n",
        "    #print('best_conf_mat_diag : {}'.format(np.diag(best_conf_mat)))\n",
        "    print('SED Metrics: ER_overall: {}, F1_overall: {}'.format(sed_scores[0], sed_scores[1]))\n",
        "    print('DOA Metrics: doa_loss_gt: {}, doa_loss_pred: {}, good_pks_ratio: {}'.format(\n",
        "        doa_scores[1], doa_scores[2], doa_scores[5] / float(sed_gt.shape[0])))\n",
        "    \n",
        "print_generic_evaluation(model, 'ansim', 1, 1)\n",
        "#print_generic_evaluation(model, 'ansim', 1, 2)\n",
        "#print_generic_evaluation(model, 'ansim', 1, 3)\n",
        "print_sed_doa_scores(model, 'ansim', 1, 1)\n",
        "#print_sed_doa_scores(model, 'ansim', 1, 2)\n",
        "#print_sed_doa_scores(model, 'ansim', 1, 3)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datagen_mode: test, nb_files: 60, nb_classes:11\n",
            "nb_frames_file: 5166, feat_len: 256, nb_ch: 8, label_len:33\n",
            "\n",
            "Dataset: ansim, ov: 1, split: 1\n",
            "batch_size: 16, seq_len: 512, shuffle: False\n",
            "label_dir: /content/drive/My Drive/folder/base_folder/label_ov1_split1_nfft512_regr0\n",
            " feat_dir: /content/drive/My Drive/folder/base_folder/spec_ov1_split1_30db_nfft512_norm\n",
            "\n",
            "37/37 [==============================] - 139s 4s/step\n",
            "Accuracy and Loss evaluation for dataset ansim ov 1 split 1\n",
            "loss 0.3595114487248498\n",
            "sed_out_loss 0.04220033157616854\n",
            "doa_out_loss 0.006346222390798298\n",
            "sed_out_acc 0.9881168813318819\n",
            "doa_out_acc 0.39690007390202703\n",
            "Datagen_mode: test, nb_files: 60, nb_classes:11\n",
            "nb_frames_file: 5166, feat_len: 256, nb_ch: 8, label_len:33\n",
            "\n",
            "Dataset: ansim, ov: 1, split: 1\n",
            "batch_size: 16, seq_len: 512, shuffle: False\n",
            "label_dir: /content/drive/My Drive/folder/base_folder/label_ov1_split1_nfft512_regr0\n",
            " feat_dir: /content/drive/My Drive/folder/base_folder/spec_ov1_split1_30db_nfft512_norm\n",
            "\n",
            "nb_batch in test: 37\n",
            "37/37 [==============================] - 134s 4s/step\n",
            "SED Metrics: ER_overall: 0.16358695652173913, F1_overall: 0.8986945169712792\n",
            "DOA Metrics: doa_loss_gt: 0.284144237211696, doa_loss_pred: 0.23354051410120497, good_pks_ratio: 0.9289022909628378\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}