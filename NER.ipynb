{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiapocci/PhilosopherRank/blob/master/NER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0EkabEj_ah5",
        "colab_type": "text"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcg7xL1K7yyZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "!pip3 install -U spacy[cuda92]\n",
        "!python3 -m spacy download en_core_web_lg\n",
        "#https://stackoverflow.com/questions/54334304/spacy-cant-find-model-en-core-web-sm-on-windows-10-and-python-3-5-3-anacon\n",
        "!python3 -m spacy link en_core_web_lg en_lg\n",
        "!pip3 install fast-pagerank\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "import pprint\n",
        "from nltk.tokenize import word_tokenize\n",
        "import time\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "nlp = spacy.load(\"en_lg\")\n",
        "spacy.prefer_gpu()\n",
        "import numpy as np\n",
        "from scipy import sparse\n",
        "\n",
        "from fast_pagerank import pagerank\n",
        "from fast_pagerank import pagerank_power\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCF3XNrOyZGk",
        "colab_type": "text"
      },
      "source": [
        "# ***Testing Dataset***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_xqGWf8yWr1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "testset = {}\n",
        "phrases_influence=[[\"He was an influence of her\",[\"her\"],[\"He\"]],\n",
        "                   [\"Jhon was an influence of Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Milton was the main influence of Mallio and Tullio\",[\"Mallio\",\"Tullio\"],[\"Milton\"]],\n",
        "                   [\"Jhon's influence on Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Markov's influence on Tito is the main reason of \\\"La Bella e la Bestia\\\", the main work of Tito's career. \",[\"Tito\"],[\"Markov\"]],\n",
        "                   [\"Jhon was Mark's influence\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"At the university she was introduced to the writings of Aristotle and Plato, who would be her greatest influence and counter-influence respectively\",[\"she\"],[\"Aristotele\", \"Plato\"]],\n",
        "                   [\"Jhon had influence on Mark's work\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Hegel had an important influence on all the different works of Einstein career\",[\"Einstein\"],[\"Hegel\"]],\n",
        "                   [\"Mark cites Jhon as an influence\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Hegel cited Shopenauer as the main influence of his work\",[\"Hegel\"],[\"Shopenauer\"]],\n",
        "                   [\"Jhon was cited by Mark as an influence\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Adler is cited as an influence on John Milton's testament\",[\"Jhon\", \"Milton\"],[\"Adler\"]]]\n",
        "phrases_influences=[[\"influences include him\",[],[\"him\"]],\n",
        "                   [\"influences include Jhon\",[],[\"Jhon\"]],\n",
        "                   [\"influences of his work include Jhon Milton and the author of  \\\"La Casa\\\", Rick Morty\",[],[\"Jhon\", \"Milton\",\"Rick\",\"Morty\"]],\n",
        "                   [\"Jhon and Adam were Mark's influences\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Aristotele, Anassagora and Pluto were Antichiola main influences\",[\"Antichiola\"],[\"Pluto\",\"Aristotele\",\"Anassagora\"]],\n",
        "                   [\"Jhon and Adam were influences of Mark\",[\"Mark\"],[\"Jhon\",\"Adam\"]],\n",
        "                   [\"Macchiavelli and Dante Alighieri where the main influences of Boccaccio's Decameron\",[\"Boccaccio\"],[\"Macchiavelli\",\"Dante\", \"Alighieri\"]]]\n",
        "phrases_influenced=[[\"He was influenced by him\",[\"He\"],[\"him\"]],\n",
        "                   [\"Mark was influenced by Jhon\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Adler was also influenced by the philosophies of Immanuel Kant, Friedrich Nietzsche, Rudolf Virchow and the statesman Jan Smuts\",[\"Adler\"],[\"Immanuel\", \"Kant\", \"Friedrich\", \"Nietzsche\", \"Rudolf\", \"Virchow\", \"Jan\", \"Smuts\"]],\n",
        "                   [\"Jhon has influenced Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Macchiavelli with his work have deeply influenced the philosophies of Mathma Ghandi\",[\"Mathma\",\"Ghandi\"],[\"Macchiavelli\"]],\n",
        "                   [\"Jhon influenced Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Anassagora influenced Pitagora on the ideas regarding geometry\",[\"Pitagora\"],[\"Anassagora\"]],\n",
        "                   [\"Mark's work was influenced by Jhon\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Gandhi's \\\"Power to the Man\\\" was influenced by the medioeval thinker Mark Robben\",[\"Ghandi\"],[\"Mark\", \"Robben\"]],\n",
        "                   [\"Jhon's work influenced Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Marconi's work on the electromagnetic field influenced Einstein's ideas of photon's transmission\",[\"Einstein\"],[\"Marconi\"]],\n",
        "                   [\"Jhon influenced Mark's work\",[\"Mark\"],[\"Jhon\"]],\n",
        "                   [\"Pluto influenced the idea of time of Aristotele and Minos\",[\"Aristotele\", \"Minos\"],[\"Pluto\"]]]\n",
        "phrases_inspire=[\n",
        "                    [\"He seemed to inspire her\",[\"her\"],[\"He\"]],\n",
        "                    [\"These revolutionizing ideas of Wang Yangming would later inspire prominent Japanese thinkers like Motoori Norinaga\",[\"Mootori Norinaga\"],[\"Wang Yangming\"]],\n",
        "                    [\"John's work inspire Mark\",[\"John\"],[\"Mark\"]]\n",
        "                ]\n",
        "phrases_inspiration=[\n",
        "                        [\"John was inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"Rozanov is the main source of inspiration for Dmitry Galkovsky\",[\"Dmitry Galkovsky\"],[\"Rozanov\"]],\n",
        "                        [\"Jhon and Adam became inspiration for Mark\",[\"Mark\"],[\"John and Adam\"]],\n",
        "                        [\"Jhon's work provided inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"He got the inspiration for this text from Schleiermacher ’ s Über die Religion \",[\"He\"],[\"Schleiermacher\"]],\n",
        "                        [\"Jhon's work was inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"While Murdoch 's thought is an inspiration for Conradi\",[\"Conradi\"],[\"Murdoch\"]],\n",
        "                        [\"Jhon's work served as inspiration to Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                        [\"Lucian 's True Story inspired Cyrano de Bergerac , whose writings later served as inspiration for Jules Verne \",[\"Cyrano de Bergerac\", \"Jules Verne\"],[\"Lucian\"]],\n",
        "                        [\"Mark took inspiration from John\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"He also took inspiration from phenomenologist epistemology\",[\"He\"],[\"phenomenologist epistemology\"]],\n",
        "                        [\"Mark drew inspiration from John\", [\"Mark\"], [\"John\"]],\n",
        "                        [\"In particular , he drew inspiration from a Chinese Buddhist master named Tao-cho\",[\"he\"],[\"Tao-cho\"]],\n",
        "                        [\"Mark provided inspiration to John\",[\"John\"],[\"Mark\"]]\n",
        "                    ]\n",
        "phrases_inspired=[\n",
        "                    [\"He was inspired by him\",[\"He\"],[\"him\"]],\n",
        "                    [\"Mark have inspired Jhon\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"Jhon had been inspired by Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"In it , Petrarch claimed to have been inspired by Philip V of Macedon\",[\"Petrarch\"],[\"Philip V of Macedon\"]],\n",
        "                    [\"Jhon's thinking was inspired by Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"Newton 's work on infinite series was inspired by Simon Stevin 's decimals\",[\"Newton\"],[\"Simon Stevin\"]],\n",
        "                    [\"Jhon's work was inspired by Marks\",[\"John\"],[\"Marks\"]],\n",
        "                    [ \"Schiller was inspired by the play Julius of Tarent by Johann Anton Leisewitz .\",[\"Schiller\"],[\"Johann Anton Leisewitz\"]],\n",
        "                    [ \"Mark was inspired by Jhon\",[\"Mark\"],[\"John\"]],\n",
        "                    [\"As a youth , he was inspired by Mencius ’ proposition\",[\"he\"],[\"Mencius\"]],\n",
        "                    [\"Jhon inspired Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [ \"It also inspired him to take falsifiability as his criterion of demarcation between what is , and is not , genuinely scientific\",[\"him\"],[\"It\"]],\n",
        "                    [\"Jhon inspired Mark's work\",[\"Mark\"],[\"John\"]],\n",
        "                    [ \"Spinoza inspired the poet Shelley to write his essay\",[\"Shelley\"],[\"Spinoza\"]]\n",
        "                  ]\n",
        "\n",
        "testset[\"phrases_influence\"] = phrases_influence\n",
        "testset[\"phrases_influenced\"] = phrases_influenced\n",
        "testset[\"phrases_influences\"] = phrases_influences\n",
        "testset[\"phrases_inspiration\"] = phrases_inspiration\n",
        "testset[\"phrases_inspired\"] = phrases_inspired\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWFl--Pruu-j",
        "colab_type": "text"
      },
      "source": [
        "#***Import JSON articles***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDR8TdRiyuvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "{\n",
        "    \"philosopher\": \"name\",\n",
        "    \"article\": \"plaintext_article\",\n",
        "    \"pageid\": \"id\",\n",
        "    \"table_influenced\": \n",
        "        [\n",
        "            \"name_of_someone_philosopher_influenced_by\"\n",
        "        ]\n",
        "    \"table_influences\":\n",
        "        [\n",
        "\n",
        "            \"name_of_someone_philosopher_influences\"\n",
        "        ]\n",
        "}\n",
        "\"\"\"\n",
        "#open the file\n",
        "with open('/content/drive/My Drive/folder/result_3.json') as f:\n",
        "  jsonlist = json.load(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NU3jhlTPcgD",
        "colab_type": "text"
      },
      "source": [
        "# ***Text Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4C1w8OESdrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#HIM\n",
        "#divide in sentences the article\n",
        "\n",
        "#eliminate sentences that don't include influenc -e, -ed, -es, -ing etc\n",
        "\n",
        "#pattern matching on patterns (see language analysis)\n",
        "\n",
        "#Entity recognition and recostruction\n",
        "\n",
        "#US\n",
        "\"mark influenced jhon. Today is friday\"\n",
        "#divide in sentences the article\n",
        "\"mark influenced jhon\"\n",
        "\"Today is friday\"\n",
        "#eliminate sentences that don't include influenc -e, -ed, -es, etc\n",
        "\"mark influenced jhon\"\n",
        "\n",
        "#pattern matching on patterns (using spacy \n",
        "?)\n",
        "[x = \"mark\", y = \"jhon\"]\n",
        "\n",
        "#Entity recognition and recostruction(here we have a proble, when he had Hendrix he could )\n",
        "\"\"\"\n",
        "\n",
        "#pages that are errors\n",
        "page_errors = [\"13692155\", \"225052\", \"63948\", \"3072809\"] \n",
        "start = time.time()\n",
        "for elem in jsonlist:\n",
        "    if elem[\"pageid\"] in page_errors:\n",
        "        continue\n",
        "\n",
        "    #divide in sentences the article\n",
        "    sent_list = nltk.sent_tokenize(elem[\"article\"])\n",
        "    \n",
        "    sent_list = [word_tokenize(i) for i in sent_list]\n",
        "\n",
        "    influence_list = []\n",
        "    influence_declinations = [\"influence\", \"influenced\", \"influences\", \"inspired\", \"inspiration\"]\n",
        "\n",
        "\n",
        "    for word_list in sent_list:\n",
        "        temp = [x for x in word_list if x in influence_declinations]\n",
        "        if len(temp) != 0:\n",
        "            influence_list.append(' '.join(word for word in word_list))\n",
        "\n",
        "    new_list = []\n",
        "    for sent in influence_list:\n",
        "        new_list.append(sent)\n",
        "        #displacy.render(sent, style=\"dep\", jupyter=True)\n",
        "    elem[\"article\"] = new_list\n",
        "print(time.time() - start)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lDBlrWxd6Bzb",
        "colab_type": "text"
      },
      "source": [
        "# ***La cosa piu logica da fare***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWAsMfCN6NWS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def regex(phrase):\n",
        "  left = []\n",
        "  right = []\n",
        "  influencers = []\n",
        "  influenced = []\n",
        "\n",
        "  try:\n",
        "    left = re.split(r'have[\\s].*[iI]nfluenced[\\s.,]', phrase ,2)[0]\n",
        "    right = re.split(r'have[\\s].*[iI]nfluenced[\\s.,]', phrase ,2)[1]\n",
        "    influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "    influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "  except:\n",
        "    try:\n",
        "      left = re.split(r'was[\\s].*[iI]nfluenced[\\s.,]', phrase ,2)[0]\n",
        "      right = re.split(r'was[\\s].*[iI]nfluenced[\\s.,]', phrase ,2)[1]\n",
        "      influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "      influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "    except:\n",
        "      try:\n",
        "        left = re.split(r'[iI]nfluenced[\\s]by[\\s.,]', phrase ,2)[0]\n",
        "        right = re.split(r'[iI]nfluenced[\\s]by[\\s.,]', phrase ,2)[1]\n",
        "        influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "        influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "      except:\n",
        "        try:\n",
        "          left = re.split(r'has[\\s][iI]nfluenced[\\s.,]', phrase ,2)[0]\n",
        "          right = re.split(r'has[\\s][iI]nfluenced[\\s.,]', phrase ,2)[1]\n",
        "          influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "          influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "        except:\n",
        "          try:\n",
        "            left = re.split(r'[iI]nfluenced[\\s.,]', phrase ,2)[0]\n",
        "            right = re.split(r'[iI]nfluenced[\\s.,]', phrase ,2)[1]\n",
        "            influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "            influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "          except:\n",
        "            try:\n",
        "              left = re.split(r'[iI]nfluences?[\\s].*on[\\s.,]', phrase ,2)[0]\n",
        "              right = re.split(r'[iI]nfluences?[\\s].*on[\\s.,]', phrase ,2)[1]\n",
        "              influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "              influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "            except:\n",
        "              try:\n",
        "                left = re.split(r'[iI]nfluences?[\\s].*of[\\s.,]', phrase ,2)[0]\n",
        "                right = re.split(r'[iI]nfluences?[\\s].*of[\\s.,]', phrase ,2)[1]\n",
        "                influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "                influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "              except:\n",
        "                try:\n",
        "                  left = re.split(r'[iI]nfluences?[\\s].*include[\\s.,]', phrase ,2)[0]\n",
        "                  right = re.split(r'[iI]nfluences?[\\s].*include[\\s.,]', phrase ,2)[1]\n",
        "                  influencers = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(right))\n",
        "                  influenced = re.findall(r'[A-Z][a-z\\']+[\\s.,]?', str(left))\n",
        "                except:\n",
        "                  influencers = []\n",
        "                  influenced = []\n",
        "  print('Phrase: ' + phrase)\n",
        "  print('Influencers: ' + str(influencers))\n",
        "  print('Influenced: ' + str(influenced)+'\\n')\n",
        "  return(influenced,influencers)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoUrPI0ElqvT",
        "colab_type": "text"
      },
      "source": [
        "# ***Testing Mattia***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aX3VKRO7ltYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for phrase in phrases_influences:\n",
        "  regex(phrase)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW3Mf9UlSeKx",
        "colab_type": "text"
      },
      "source": [
        "# ***Processing Giuliano(Spacy Dependencies)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rkKZ0aFSn-V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "------------------HIS APPROACH-------------------------\n",
        "1. X cite(s|d) Y1, Y2, …, Yn as (an) influence(s)\n",
        "2. X was influenced by Y1, Y2, …, Yn\n",
        "3. Y has been cited as an influence by X1, X2, …, Xn\n",
        "4. Y influence on X1, X2, …, Xn …\n",
        "5. Y1, Y2, …, Yn influenced hi(m|s) …\n",
        "\n",
        "\n",
        "------------------OUR APPROACH-------------------------\n",
        "Influence:\n",
        "X be an influence (of/on/for/to) Y \n",
        "X's influence (of/on/for/to) Y\n",
        "X's have influence on Y\n",
        "X be Y's influence\n",
        "Y cite X as influence\n",
        "X was cited as influence by Y\n",
        "\n",
        "\n",
        "influences:\n",
        "influences (include/of) X\n",
        "X be Y's influences\n",
        "X and X were influences of Y\n",
        "\n",
        "\n",
        "influencing:\n",
        "none\n",
        "\n",
        "\n",
        "influenced:\n",
        "Y be influenced by X\n",
        "X have influenced Y\n",
        "X influenced Y\n",
        "Y's thinking was influenced by X\n",
        "X influenced Y's work\n",
        "X's work influenced Y\n",
        "\n",
        "\n",
        "X ispiratore Y ispirante\n",
        "inspired\n",
        "Y be influenced by X\n",
        "X have inspired Y\n",
        "Y had been inspired by X\n",
        "Y's thinking/work was inspired by X\n",
        "Y was inspired by X\n",
        "X inspired Y\n",
        "\n",
        "\n",
        "inspire\n",
        "none\n",
        "\n",
        "\n",
        "inspiration\n",
        "X became/was inspiration for Y\n",
        "X's work provided/was inspiration for Y\n",
        "X's work served as inspiration to Y\n",
        "Y took/drew inspiration from X\n",
        "X provided inspiration to Y\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "def is_verb(phrase):\n",
        "    res = re.search(r'influenced\\b', phrase) or re.search(r'inspired\\b', phrase)\n",
        "    return res is not None\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Prints dependencies and displacy visuals for a phrase\n",
        "Params: sent, a sentence\n",
        "Returns: -\n",
        "\"\"\"\n",
        "def get_info(sent):\n",
        "    print(sent)\n",
        "    doc = nlp(sent)\n",
        "    displacy.render(doc, style=\"dep\", jupyter=True)  \n",
        "    for token in doc:\n",
        "        print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "                [child for child in token.children])\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Spacy processing\n",
        "Params: phrase, a phrase\n",
        "Returns:    influenced, list of influenced chunks\n",
        "            influencers, list of influencers chunks\n",
        "\"\"\"\n",
        "def process_spacy(phrase):\n",
        "    if is_verb(phrase):\n",
        "        return process_verb(phrase)\n",
        "    else:\n",
        "        return process_name(phrase)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Process influence or inspiration phrase\n",
        "Params: phrase, a phrase tagged \"influence\" or \"inspiration\"\n",
        "Returns:    influenced, list of influenced chunks\n",
        "            influencers, list of influencers chunks\n",
        "\n",
        "\"\"\"\n",
        "#add climbing three for the subj\n",
        "def process_name(phrase):\n",
        "    influenced = []\n",
        "    influencers = []\n",
        "    name = [\"influence\", \"inspiration\", \"influences\"]\n",
        "    doc = nlp(phrase)\n",
        "    compounds = []\n",
        "    for token in doc:\n",
        "        #è un soggetto passivo, ex jhon is cited as an influence \n",
        "        if token.dep_ == \"nsubjpass\" and token.head.pos_ == \"VERB\" :\n",
        "            influencers.append(token.text)\n",
        "\n",
        "        #è un soggetto attivo, ex mark was an influence\n",
        "        if token.dep_ == \"nsubj\" and token.head.pos_ == \"AUX\":\n",
        "            influencers.append(token.text)\n",
        "\n",
        "        #è un soggetto attivo, ex mark cited jhon as an influence\n",
        "        if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
        "            influenced.append(token.text)\n",
        "        \n",
        "        #è un oggetto\n",
        "        if token.dep_ in [\"pobj\", \"conj\", \"appos\", \"dobj\"]:\n",
        "            flag = 0\n",
        "            tok = token.text\n",
        "            while flag == 0:\n",
        "                if token.head.text in name:\n",
        "                    #see if it is passive or active\n",
        "                    if \"auxpass\" in [x.dep_ for x in token.head.children]:\n",
        "                        influencers.append(tok)\n",
        "                    else:\n",
        "                        influenced.append(tok)\n",
        "                    flag = 1\n",
        "                elif token.head.text == \"cited\" or token.head.text == \"cites\":\n",
        "                    if token.dep_ == \"agent\":\n",
        "                        influenced.append(tok)\n",
        "                    else:\n",
        "                        influencers.append(tok)\n",
        "                    flag = 1\n",
        "                elif token.head.pos_ == \"VERB\":\n",
        "                    if \"influence\" in [x.text for x in token.head.children] or \"influences\" in [x.text for x in token.head.children] or \"inspiration\" in [x.text for x in token.head.children]:\n",
        "                        print(\"ok\")\n",
        "                        influencers.append(tok)\n",
        "                    flag = 1\n",
        "                elif token.head.dep_ in [\"prep\", \"agent\", \"conj\", \"appos\", \"dobj\", \"pobj\"]:\n",
        "                    token = token.head\n",
        "                elif token.head.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
        "                    #è un soggetto passivo, ex jhon is cited as an influence \n",
        "                    if token.dep_ == \"nsubjpass\" and token.head.pos_ == \"VERB\" :\n",
        "                        influencers.append(token.text)\n",
        "\n",
        "                    #è un soggetto attivo, ex mark was an influence\n",
        "                    if token.dep_ == \"nsubj\" and token.head.pos_ == \"AUX\":\n",
        "                        influencers.append(token.text)\n",
        "\n",
        "                    #è un soggetto attivo, ex mark cited jhon as an influence\n",
        "                    if token.dep_ == \"nsubj\" and token.head.pos_ == \"VERB\":\n",
        "                        influenced.append(token.text)\n",
        "                    \n",
        "                    flag = 1\n",
        "                else:\n",
        "                    flag = 1\n",
        "\n",
        "                \n",
        "                \n",
        "        #è un genitivo\n",
        "        if token.dep_ == \"poss\":\n",
        "            tok = token.text\n",
        "            token = token.head\n",
        "            flag = 0\n",
        "            while flag == 0:\n",
        "                if token.text in name:\n",
        "                    if token.dep_ in [\"attr\", \"pobj\", \"dobj\"]:\n",
        "                        influenced.append(tok)\n",
        "                    else:\n",
        "                        influencers.append(tok)\n",
        "                    flag = 1\n",
        "                elif token.head.dep_ in [\"prep\", \"agent\", \"conj\", \"appos\", \"dobj\", \"pobj\"]:\n",
        "                    token = token.head\n",
        "                else:\n",
        "                    flag = 1\n",
        "\n",
        "            \n",
        "                \n",
        "        #catch compounds\n",
        "        if token.dep_ == \"compound\":\n",
        "            compounds.append(token)\n",
        "\n",
        "    #look for compound names\n",
        "    for token in compounds:\n",
        "        if token.head.text in influenced:\n",
        "            influenced.append(token.text)\n",
        "        if token.head.text in influencers:\n",
        "            influencers.append(token.text)\n",
        "    return influenced, influencers\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "Process influenced or inspired phrase\n",
        "Params: phrase, a phrase tagged \"influencer\" or \"inspired\"\n",
        "Returns:    influenced, list of influenced chunks\n",
        "            influencers, list of influencers chunks\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "#aggiungi compound e influenced\n",
        "#add climbing three for the subj\n",
        "def process_verb(phrase):\n",
        "    influenced = []\n",
        "    influencers = []\n",
        "    doc = nlp(phrase)\n",
        "    verbs = [\"influenced\",\"inspired\"]\n",
        "    compounds = []\n",
        "    for token in doc:\n",
        "        #SOGGETTO\n",
        "        #è un soggetto passivo, ex Mark was infuenced\n",
        "        if token.dep_ == \"nsubjpass\" and token.head.text in verbs :\n",
        "            influenced.append(token.text)\n",
        "\n",
        "        #è un soggetto attivo, ex Jhon influenced\n",
        "        if token.dep_ == \"nsubj\":\n",
        "            if token.head.text in verbs:\n",
        "                influencers.append(token.text)\n",
        "            for ch in token.head.children:\n",
        "                if \"auxpass\" in [x.dep_ for x in ch.children] and ch.text in verbs:\n",
        "                    influenced.append(token.text)\n",
        "                elif ch.text in verbs:\n",
        "                    influencers.append(token.text)\n",
        "\n",
        "\n",
        "\n",
        "        #è un oggetto\n",
        "        if token.dep_ in [\"pobj\", \"conj\", \"appos\", \"dobj\"]:\n",
        "            flag = 0\n",
        "            tok = token.text\n",
        "            while flag == 0:\n",
        "                if token.head.dep_ in [\"prep\", \"agent\", \"conj\", \"appos\", \"dobj\", \"pobj\"]:\n",
        "                    token = token.head\n",
        "                elif token.head.text in verbs:\n",
        "                    #see if it is passive or active\n",
        "                    if \"auxpass\" in [x.dep_ for x in token.head.children]:\n",
        "                        influencers.append(tok)\n",
        "                    else:\n",
        "                        influenced.append(tok)\n",
        "                    flag = 1\n",
        "                elif token.head.dep_ in [\"nsubj\", \"nsubjpass\"]:\n",
        "\n",
        "                    token = token.head\n",
        "                    if token.dep_ == \"nsubjpass\" and token.head.text in verbs :\n",
        "                        influenced.append(tok)\n",
        "\n",
        "                    #è un soggetto attivo, ex Jhon influenced\n",
        "                    if token.dep_ == \"nsubj\":\n",
        "                        if token.head.text in verbs:\n",
        "                            influencers.append(tok)\n",
        "                        for ch in token.head.children:\n",
        "                            if \"auxpass\" in [x.dep_ for x in ch.children] and ch.text in verbs:\n",
        "                                influenced.append(tok)\n",
        "                            elif ch.text in verbs:\n",
        "                                influencers.append(tok) \n",
        "                    flag = 1                   \n",
        "                else:\n",
        "                    flag = 1\n",
        "        \n",
        "\n",
        "        #è un genitivo\n",
        "        if token.dep_ == \"poss\":\n",
        "            tok = token.text\n",
        "            token = token.head\n",
        "            #di un soggetto\n",
        "            if token.dep_== \"nsubjpass\" and token.head.text in verbs :\n",
        "                influenced.append(tok)\n",
        "            if token.dep_ == \"nsubj\" and token.head.text in verbs:\n",
        "                influencers.append(tok)\n",
        "            #di un oggetto\n",
        "            if token.dep_ in [\"pobj\", \"conj\", \"appos\", \"dobj\"]:\n",
        "                flag = 0\n",
        "                while flag == 0:\n",
        "                    if token.head.dep_ in [\"prep\", \"agent\", \"conj\", \"appos\", \"dobj\", \"pobj\"]:\n",
        "                        token = token.head\n",
        "                    elif token.head.text in verbs:\n",
        "                        #see if it is passive or active\n",
        "                        if \"auxpass\" in [x.dep_ for x in token.head.children]:\n",
        "                            influencers.append(tok)\n",
        "                        else:\n",
        "                            influenced.append(tok)\n",
        "                        flag = 1\n",
        "                    else:\n",
        "                        flag = 1\n",
        "\n",
        "\n",
        "        #catch compounds\n",
        "        if token.dep_ == \"compound\":\n",
        "            compounds.append(token)\n",
        "\n",
        "    #look for compound names\n",
        "    for token in compounds:\n",
        "        if token.head.text in influenced:\n",
        "            influenced.append(token.text)\n",
        "        if token.head.text in influencers:\n",
        "            influencers.append(token.text)\n",
        "    return influenced, influencers\n",
        "    \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2LAGk9n46KC",
        "colab_type": "text"
      },
      "source": [
        "# ***Testing Giuliano***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwU02BGMvYMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "for phr in phrases_influenced:\n",
        "    get_info(phr[0])\n",
        "    influenced, influencer = process_verb(phr[0])\n",
        "    print(\"______EVAL______\")\n",
        "    print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "    print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "    print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "    print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "for phr in phrases_inspired:\n",
        "    get_info(phr[0])\n",
        "    influenced, influencer = process_verb(phr[0])\n",
        "    print(\"______EVAL______\")\n",
        "    print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "    print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "    print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "    print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\"\"\"\n",
        "\n",
        "for phr in phrases_influence:\n",
        "    get_info(phr[0])\n",
        "    influenced, influencer = process_name(phr[0])\n",
        "    print(\"______EVAL______\")\n",
        "    print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "    print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "    print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "    print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "for phr in phrases_influences:\n",
        "    get_info(phr[0])\n",
        "    influenced, influencer = process_name(phr[0])\n",
        "    print(\"______EVAL______\")\n",
        "    print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "    print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "    print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "    print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\n",
        "print(\"--------------------------------------------------------------------------------\")\n",
        "for phr in phrases_inspiration:\n",
        "    get_info(phr[0])\n",
        "    influenced, influencer = process_name(phr[0])\n",
        "    print(\"______EVAL______\")\n",
        "    print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "    print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "    print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "    print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbO5M4vrlJzN",
        "colab_type": "text"
      },
      "source": [
        "# ***Create Processed Json***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g8Ov7FTGlpD2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Input cella:\n",
        "jsonlist = \n",
        "[\n",
        "    {\n",
        "        \"philosopher\" = \"philosopher_name\",\n",
        "        \"pageid\" = id,\n",
        "        \"article\" = \n",
        "        [\n",
        "            \"frase contenente influence\",\n",
        "\n",
        "            \"frase contenente influence\", etc\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "Output cella:\n",
        "output =\n",
        "[\n",
        "    {\n",
        "        \"philosopher\" : \"philosopher_name\",\n",
        "        \"pageid\" : id,\n",
        "        \"article\" : \n",
        "            [\n",
        "                \"frase contenente influence\",\n",
        "\n",
        "                \"frase contenente influence\" \n",
        "            ]\n",
        "\n",
        "        \"rich_article\" :\n",
        "            [\n",
        "                {\n",
        "                    'influenced': ['East ', 'Asia '],\n",
        "                    'influencers': ['Influence ', 'Zhuangzi ',\"Plato\", \"William\", \"Ralph\", \"Inge\"],\n",
        "                    'phrase': '== Influence == Zhuangzi has influenced '\n",
        "                                'thinking far beyond East Asia .'\n",
        "                }\n",
        "            ]\n",
        "    }\n",
        "\n",
        "]\n",
        "\"\"\"\n",
        "#some prints and infos\n",
        "\n",
        "#pprint.pprint(jsonlist)\n",
        "print(len(jsonlist))\n",
        "jsonlist_no_empty = [i for i in jsonlist if len(i[\"article\"]) != 0]\n",
        "print(len(jsonlist_no_empty))\n",
        "#pprint.pprint(jsonlist_no_empty)\n",
        "\n",
        "jsonlist_processed = jsonlist_no_empty\n",
        "\n",
        "for phil in jsonlist_processed:\n",
        "    rich_article = []\n",
        "    for phrase in phil[\"article\"]:\n",
        "        #use regex for regex processing or process_spacy for spacy processing\n",
        "        influenced, influencers = process_spacy(phrase)\n",
        "        elem = {}\n",
        "        elem[\"influenced\"] = influenced\n",
        "        elem[\"influencers\"] = influencers\n",
        "        elem[\"phrase\"] = phrase\n",
        "        rich_article.append(elem)\n",
        "    phil[\"rich_article\"] = rich_article\n",
        "\n",
        "#pprint.pprint(jsonlist_processed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4LFfwUCmF9L",
        "colab_type": "text"
      },
      "source": [
        "# ***Cleaning and Recostruction(Luigi)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccUTAu2cmGcY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "input =\n",
        "[\n",
        "    {\n",
        "        \"philosopher\" : \"philosopher_name\",\n",
        "        \"pageid\" : id,\n",
        "        \"article\" : \n",
        "            [\n",
        "                \"frase contenente influence\",\n",
        "\n",
        "                \"frase contenente influence\" \n",
        "            ]\n",
        "\n",
        "        \"rich_article\" :\n",
        "            [\n",
        "                {\n",
        "                    'influenced': ['East ', 'Asia '],\n",
        "                    'influencers': ['Influence ', 'Zhuangzi ',\"Plato\", \"William\", \"Ralph\", \"Inge\"],\n",
        "                    'phrase': '== Influence == Zhuangzi has influenced '\n",
        "                                'thinking far beyond East Asia .'\n",
        "                }\n",
        "            ]\n",
        "    }\n",
        "\n",
        "]\n",
        "\n",
        "output:\n",
        "[\n",
        "    {\n",
        "        \"philosopher\" : \"philosopher_name\",\n",
        "        \"pageid\" : id,\n",
        "        \"article\" : \n",
        "            [\n",
        "                \"frase contenente influence\",\n",
        "\n",
        "                \"frase contenente influence\" \n",
        "            ],\n",
        "\n",
        "        \"rich_article\" :\n",
        "            [\n",
        "                {\n",
        "                    'influenced': ['East ', 'Asia '],\n",
        "                    'influencers': ['Influence ', 'Zhuangzi ',\"Plato\", \"William\", \"Ralph\", \"Inge\"],\n",
        "                    'phrase': '== Influence == Zhuangzi has influenced '\n",
        "                                'thinking far beyond East Asia .'\n",
        "                }\n",
        "            ]\n",
        "        \"influenced\" :\n",
        "            [\n",
        "                \"list of influenced after cleaning\"\n",
        "            ],\n",
        "\n",
        "        \"influencers\" :\n",
        "            [\n",
        "                \"list of influencers after cleaning\"\n",
        "            ]\n",
        "    }\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "                \"frase contenente influence\" = \"Jhon Milton influenced Ghandi and Hannibal Bures' \"Power to the Man\"\"\n",
        "                [\n",
        "                    list of influencers = [\"Jhon\", \"Milton\"] --> \"Jhon Milton\"\n",
        "                ],\n",
        "                [\n",
        "                    list of influenced = [\"Ghandi\", \"Hannibal\", \"Bures\", \"Power\", \"Man\"] --> \"Mathma Ghandi\", \"Hannibal Bures\"\n",
        "                ]\n",
        "                \"him\" --> nome del philosopher\n",
        "\"\"\"\n",
        "\n",
        "def create_phil_list(jsonlist_no_empty):\n",
        "    phil_name_list = []\n",
        "    for art in jsonlist_no_empty:\n",
        "        phil_name_list.append(art['philosopher'])\n",
        "    return phil_name_list\n",
        "\n",
        "# \"title della pagina della filosofia\": \"lista dei title degli hyperlink\"\n",
        "\n",
        "def create_list_of_current_thinking(diz):\n",
        "    for current in diz:\n",
        "        new_lst = []\n",
        "        for presunt_phil in diz[current]:\n",
        "            if presunt_phil in phil_name_list:\n",
        "                new_lst.append(presunt_phil)\n",
        "        diz[current] = new_lst\n",
        "    return diz\n",
        "\n",
        "\n",
        "def search_on_cluster(presunt_thinking_current):\n",
        "    #IE Western philosophy\n",
        "    if presunt_thinking_current in thinking_current:\n",
        "        print(\"DEBUG: \", thinking_current[presunt_thinking_current])\n",
        "        return thinking_current[presunt_thinking_current]\n",
        "    else:\n",
        "        return []\n",
        "\n",
        "\n",
        "def add_names(philosopher):\n",
        "    nouns = [\"he\", \"He\", \"she\", \"She\", \"him\", \"Him\", \"his\", \"His\", \"hers\",\n",
        "             \"Hers\", \"her\", \"Her\", \"they\", \"They\", \"was\", \"it\", \"is\"]\n",
        "    for token_rich in philosopher[\"rich_article\"]:\n",
        "        for elem in token_rich[\"influenced\"]:\n",
        "            if elem in nouns:\n",
        "                token_rich['influenced'].remove(elem)\n",
        "        for elem in token_rich[\"influencers\"]:\n",
        "            if elem in token_rich[\"influencers\"]:\n",
        "                token_rich['influencers'].remove(elem)\n",
        "    return philosopher\n",
        "\n",
        "\n",
        "\n",
        "def myfunc(phil):\n",
        "    mtch_lst = []\n",
        "    for p in phil_name_list:\n",
        "        if phil in p:\n",
        "            mtch_lst.append(p)\n",
        "    return mtch_lst\n",
        "\n",
        "\n",
        "\n",
        "def founded_name(name,influencers):\n",
        "    splittato = name.split() \n",
        "    for part_of_name in splittato: #se trovi grazie al nome --> cancella il cognome ancora presente\n",
        "        try:\n",
        "            influencers.remove(part_of_name)\n",
        "        except:\n",
        "            continue\n",
        "    return name\n",
        "\n",
        "def aux_func(lst):\n",
        "    new_lst = []\n",
        "    lst = [word for word in lst if word not in stopwords.words('english')]\n",
        "    for phil in lst:\n",
        "        # if phil in thinking_current:\n",
        "        #     new_lst = new_lst + search_on_cluster(phil)\n",
        "        #     continue\n",
        "        if phil in phil_name_list:\n",
        "            new_lst.append(phil)\n",
        "            print(\"EASYYY !! bevutooo: \",phil)\n",
        "        else: #nome composto da piu stringhe ?\n",
        "            possible_names = myfunc(phil) \n",
        "            if len(possible_names) == 1: #cioccato\n",
        "                new_lst.append(founded_name(possible_names[0], lst))\n",
        "                print(\"EEhh, cioccato quasi subito --> \", possible_names[0])\n",
        "            else:\n",
        "                #cerca nomi nella lista per fare nome + cognome\n",
        "                for name in possible_names:\n",
        "                    splittato = name.split()\n",
        "                    try:\n",
        "                        splittato.remove(phil) #rimuovi da [William, Alston] William\n",
        "                    except:\n",
        "                        print(\"This is not the phil you are looking for: \", name)\n",
        "                    for word in splittato:\n",
        "                        if word in lst: #if Alston è nella listsa di influencers vuol dire che era William ALston \n",
        "                            founded_name(name,lst) \n",
        "                            new_lst.append(name)\n",
        "                            print(\"aggiunto --> \", name)\n",
        "    return new_lst      \n",
        "\n",
        "\n",
        "def reconstruct_phil(output, phil_name_list, thinking_current):\n",
        "    for match in output:\n",
        "        match = add_names(match)\n",
        "        art = match[\"rich_article\"]\n",
        "        match['influenced'] = [] \n",
        "        match['influencers'] = []\n",
        "        for i in art:\n",
        "            new_lst_influenced = aux_func(i['influenced'])\n",
        "            new_lst_influencers = aux_func(i['influencers'])\n",
        "            new_lst_influenced = [x for x in new_lst_influenced if x != match['philosopher']]\n",
        "            new_lst_influencers = [x for x in new_lst_influencers if x != match['philosopher']]\n",
        "            match['influenced'] = match['influenced'] + new_lst_influenced\n",
        "            match['influencers'] = match['influencers'] + new_lst_influencers\n",
        "        #aggiungi le tables\n",
        "        try:\n",
        "            table_influenced = []\n",
        "            for x in match['table']['influenced']:\n",
        "                table_influenced = table_influenced + search_on_cluster(x)\n",
        "                if x in phil_name_list:\n",
        "                    table_influenced.append(x)\n",
        "            match['influenced'] = match['influenced'] + table_influenced\n",
        "        except:\n",
        "            print(\"No influenced\\n\")\n",
        "        try:\n",
        "            #match['influencers'] = match['influencers'] + [x for x in match['table']['influenced'] if x in phil_name_list]\n",
        "            table_influencers = []\n",
        "            for x in match['table']['influencers']:\n",
        "                table_influencers = table_influencers + search_on_cluster(x)\n",
        "                if x in phil_name_list:\n",
        "                    table_influencers.append(x)\n",
        "            match['influencers'] = match['influencers'] + table_influencers\n",
        "        except:\n",
        "            print(\"No influencers\")\n",
        "        #elimina doppioni\n",
        "        match['influenced'] = list(set(match['influenced']))\n",
        "        match['influencers'] = list(set(match['influencers']))\n",
        "    return output\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "with open('/content/drive/My Drive/folder/raw_clusters.json') as f:\n",
        "  diz = json.load(f)\n",
        "\n",
        "\n",
        "phil_name_list = create_phil_list(jsonlist_no_empty)\n",
        "\n",
        "thinking_current = create_list_of_current_thinking(diz)\n",
        "\n",
        "reconstructed_list = reconstruct_phil(jsonlist_processed,phil_name_list, thinking_current)\n",
        "\n",
        "\n",
        "#pprint.pprint([x for x in reconstructed_list if x[\"pageid\"] == \"21444\"])\n",
        "\n",
        "#pprint.pprint(add_names([x for x in reconstructed_list if x[\"pageid\"] == \"21444\"][0]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bq1AH64fsuyh",
        "colab_type": "text"
      },
      "source": [
        "# ***Pagerank***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljiAm4Ydtw4m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def find_indexes_from_names(names, jsonlist):\n",
        "    indexes = []\n",
        "    for name in names:\n",
        "        x = [x[\"index\"] for x in jsonlist if x[\"philosopher\"] == name]\n",
        "        if len(x) != 0:\n",
        "            indexes.append(x[0])\n",
        "    return indexes\n",
        "\n",
        "\n",
        "edges = []\n",
        "\n",
        "for i in range(len(jsonlist_processed)):\n",
        "    jsonlist_processed[i][\"index\"] = i\n",
        "\n",
        "for philosopher in jsonlist_processed: \n",
        "    influenced_list = find_indexes_from_names(philosopher[\"influenced\"], jsonlist_processed)\n",
        "    influencers_list = find_indexes_from_names(philosopher[\"influencers\"], jsonlist_processed)\n",
        "    philosopher[\"influenced_indexes\"] = influenced_list\n",
        "    philosopher[\"influencers_indexes\"] = influencers_list\n",
        "\n",
        "\n",
        "edges = []\n",
        "for philosopher in jsonlist_processed:\n",
        "    for infed_index in philosopher[\"influenced_indexes\"]:\n",
        "        edges.append([infed_index, philosopher[\"index\"]])\n",
        "        \n",
        "    for infers_index in philosopher[\"influencers_indexes\"]:\n",
        "        edges.append([philosopher[\"index\"], infers_index])\n",
        "\n",
        "\n",
        "A = np.array(edges)\n",
        "weights = [1 for i in range(len(edges))]\n",
        "G = sparse.csr_matrix((weights, (A[:,0], A[:,1])), shape=(len(jsonlist_processed), len(jsonlist_processed)))\n",
        "\n",
        "pr=pagerank(G, p=0.85)\n",
        "result = []\n",
        "for i in range(len(pr)):\n",
        "    name = [[\"Name\", x[\"philosopher\"], \"Influenced\", x[\"influenced\"], \"influencers\", x[\"influencers\"]] for x in jsonlist_processed if x[\"index\"] == i]\n",
        "    result.append([pr[i], name[0]])\n",
        "pprint.pprint(sorted(result, key=lambda x: x[0], reverse = True))\n",
        "\n",
        "\n",
        "from prettytable import PrettyTable\n",
        "x = PrettyTable()\n",
        "x.field_names = [\"Philosopher\", \"Rank\", \"#Influenced\", \"#Influencers\"]\n",
        "counter = 1\n",
        "for i in range(len(pr)):\n",
        "    x.add_row([jsonlist_processed[i]['philosopher'], pr[i], len(jsonlist_processed[i]['influenced']), len(jsonlist_processed[i]['influencers'])])\n",
        "x.sortby = \"Rank\"\n",
        "x.reversesort = True\n",
        "\n",
        "print(x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}