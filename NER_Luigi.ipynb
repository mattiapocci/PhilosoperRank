{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NER_Luigi.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "W0EkabEj_ah5",
        "y2LAGk9n46KC",
        "LWFl--Pruu-j",
        "KW3Mf9UlSeKx",
        "j132TVHEKK3Q"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mattiapocci/PhilosoperRank/blob/master/NER_Luigi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0EkabEj_ah5",
        "colab_type": "text"
      },
      "source": [
        "#***Imports and Drive Mount***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcg7xL1K7yyZ",
        "colab_type": "code",
        "outputId": "b87a416a-7165-4970-b1b2-37871eca0f06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "#!pip3 install -U spacy[cuda92]\n",
        "#!python3 -m spacy download en_core_web_lg\n",
        "#https://stackoverflow.com/questions/54334304/spacy-cant-find-model-en-core-web-sm-on-windows-10-and-python-3-5-3-anacon\n",
        "\n",
        "import sys\n",
        "import time\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "import json\n",
        "import spacy\n",
        "from spacy import displacy\n",
        "import nltk\n",
        "import pprint\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "nltk.download('punkt')\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "spacy.prefer_gpu()\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2LAGk9n46KC",
        "colab_type": "text"
      },
      "source": [
        "# ***Language Analysis***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cwU02BGMvYMX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "1. X cite(s|d) Y1, Y2, …, Yn as (an) influence(s)\n",
        "2. X was influenced by Y1, Y2, …, Yn\n",
        "3. Y has been cited as an influence by X1, X2, …, Xn\n",
        "4. Y influence on X1, X2, …, Xn …\n",
        "5. Y1, Y2, …, Yn influenced hi(m|s) …\n",
        "\"\"\"\n",
        "\n",
        "def get_info(sent_list):\n",
        "  for sent in sent_list:\n",
        "    print(sent)\n",
        "    doc = nlp(sent)\n",
        "    displacy.render(doc, style=\"dep\", jupyter=True)  \n",
        "    print(\"CHUNKS\")\n",
        "        \n",
        "    for chunk in doc.noun_chunks:\n",
        "        print(chunk.text, chunk.root.text, chunk.root.dep_, \n",
        "                chunk.root.head.text)\n",
        "    print(\"TREE\")\n",
        "    for token in doc:\n",
        "        print(token.text, token.dep_, token.head.text, token.head.pos_,\n",
        "                [child for child in token.children])\n",
        "\n",
        "\n",
        "def process(phrase):\n",
        "    influenced = []\n",
        "    influencers = []\n",
        "    doc = nlp(phrase)\n",
        "    compounds = []\n",
        "    for token in doc:\n",
        "        if token.dep_ == \"nsubjpass\" and token.head.text in [\"influenced\", \"influences\"] :\n",
        "            influenced.append(token.text)\n",
        "        if token.dep_ == \"nsubj\" and token.head.text in [\"influenced\", \"influences\"]:\n",
        "            influencers.append(token.text)\n",
        "        if token.dep_ == \"pobj\":\n",
        "            flag = 0\n",
        "            tok = token.text\n",
        "            children = token.children\n",
        "            while flag == 0:\n",
        "                if token.head.dep_ == \"pobj\" or token.head.dep_ in [\"prep\", \"agent\",\"conj\"]:\n",
        "                    token = token.head\n",
        "                elif token.head.text in [\"influenced\", \"influences\"]:\n",
        "                    influencers.append(tok)\n",
        "                    flag = 1\n",
        "                else:\n",
        "                    flag = 1\n",
        "        if token.dep_ == \"conj\":\n",
        "            flag = 0\n",
        "            tok = token.text\n",
        "            children = token.children\n",
        "            while flag == 0:\n",
        "                if token.head.dep_ == \"pobj\" or token.head.dep_ == \"prep\" or token.head.dep_ ==\"agent\" or token.head.dep_ ==\"conj\":\n",
        "                    token = token.head\n",
        "                elif token.head.text in [\"influenced\", \"influences\"]:\n",
        "                    influencers.append(tok)\n",
        "                    flag = 1\n",
        "                else:\n",
        "                    flag = 1\n",
        "        if token.dep_ == \"dobj\":\n",
        "            flag = 0\n",
        "            tok = token.text\n",
        "            children = token.children\n",
        "            while flag == 0:\n",
        "                if token.head.dep_ == \"pobj\" or token.head.dep_ == \"dobj\" or token.head.dep_ == \"prep\" or token.head.dep_ ==\"agent\":\n",
        "                    token = token.head\n",
        "                elif token.head.text in [\"influenced\", \"influences\"]:\n",
        "                    influencers.append(tok)\n",
        "                    flag = 1\n",
        "                else:\n",
        "                    flag = 1\n",
        "        \n",
        "        if token.dep_ == \"compound\":\n",
        "            compounds.append(token)\n",
        "    \n",
        "    for token in compounds:\n",
        "        if token.head.text in influenced:\n",
        "            influenced.append(token.text)\n",
        "        if token.head.text in influencers:\n",
        "            influencers.append(token.text)\n",
        "    return influenced, influencers\n",
        "    \n",
        "phrases=[\"Mark was influenced by Jhon\",\n",
        "         \"Jhon influenced Mark\",\n",
        "         \"Mark was an influence of Jhon and Albert\",\n",
        "         \"Jhon influenced him\",\n",
        "         \"Adler was also influenced by the philosophies of Immanuel Kant, Friedrich Nietzsche, Rudolf Virchow and the statesman Jan Smuts \",\n",
        "         \"He is cited as an influence on John Milton\"]\n",
        "\n",
        "for phr in phrases:\n",
        "  get_info([phr])\n",
        "  print(process(phr))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWFl--Pruu-j",
        "colab_type": "text"
      },
      "source": [
        "#***Import JSON articles***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDR8TdRiyuvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "{\n",
        "    \"philosopher\": \"name\",\n",
        "    \"article\": \"plaintext_article\",\n",
        "    \"pageid\": \"id\",\n",
        "    \"table_influenced\": \n",
        "        [\n",
        "            {\n",
        "                \"0\": \"name_of_someone_philosopher_influenced_by\"\n",
        "            }\n",
        "        ]\n",
        "    \"table_influences\":\n",
        "        [\n",
        "            {\n",
        "                \"0\": \"name_of_someone_philosopher_influences\"\n",
        "            }\n",
        "        ]\n",
        "}\n",
        "\"\"\"\n",
        "#open the file\n",
        "with open('/content/drive/My Drive/Wiki_dump/mattia_ground_t.json') as f:\n",
        "  jsonlist = json.load(f)\n",
        "\n",
        "phil_name_list = []\n",
        "\n",
        "for art in jsonlist:\n",
        "    phil_name_list.append(art['philosopher'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NU3jhlTPcgD",
        "colab_type": "text"
      },
      "source": [
        "# ***Text Preprocessing***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4C1w8OESdrO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#HIM\n",
        "#divide in sentences the article\n",
        "\n",
        "#eliminate sentences that don't include influenc -e, -ed, -es, -ing etc\n",
        "\n",
        "#pattern matching on patterns (see language analysis)\n",
        "\n",
        "#Entity recognition and recostruction\n",
        "\n",
        "#US\n",
        "\"mark influenced jhon. Today is friday\"\n",
        "#divide in sentences the article\n",
        "\"mark influenced jhon\"\n",
        "\"Today is friday\"\n",
        "#eliminate sentences that don't include influenc -e, -ed, -es, etc\n",
        "\"mark influenced jhon\"\n",
        "\n",
        "#pattern matching on patterns (using spacy \n",
        "?)\n",
        "[x = \"mark\", y = \"jhon\"]\n",
        "\n",
        "#Entity recognition and recostruction(here we have a proble, when he had Hendrix he could )\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "counter_influence = []\n",
        "counter_influenced = []\n",
        "counter_influences = []\n",
        "counter_influencing = []\n",
        "counter_inspired = []\n",
        "counter_inspire = []\n",
        "counter_inspiration = []\n",
        "for elem in jsonlist:\n",
        "    #divide in sentences the article\n",
        "    sent_list = nltk.sent_tokenize(elem[\"article\"])\n",
        "    \n",
        "    sent_list = [word_tokenize(i) for i in sent_list]\n",
        "\n",
        "    influence_list = []\n",
        "    influence_declinations = [\"influence\", \"influenced\", \"influences\", \"influencing\", \"inspired\", \"inspire\", \"inspiration\"]\n",
        "\n",
        "\n",
        "    for word_list in sent_list:\n",
        "        temp = [x for x in word_list if x in influence_declinations]\n",
        "        if \"influence\" in word_list:\n",
        "            counter_influence.append(word_list)\n",
        "        if \"influencing\" in word_list:\n",
        "            counter_influencing.append(word_list)\n",
        "        if \"influenced\" in word_list:\n",
        "            counter_influenced.append(word_list)\n",
        "        if \"influences\" in word_list:\n",
        "            counter_influences.append(word_list)\n",
        "        if \"inspired\" in word_list:\n",
        "            counter_inspired.append(word_list)\n",
        "        if \"inspire\" in word_list:\n",
        "            counter_inspire.append(word_list)\n",
        "        if \"inspiration\" in word_list:\n",
        "            counter_inspiration.append(word_list)\n",
        "        if len(temp) != 0:\n",
        "            influence_list.append(' '.join(word for word in word_list))\n",
        "\n",
        "    new_list = []\n",
        "    for sent in influence_list:\n",
        "        new_list.append(sent)\n",
        "        #displacy.render(sent, style=\"dep\", jupyter=True)\n",
        "    elem[\"article\"] = new_list\n",
        "print(time.time() - start)\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "influencing pisciato\n",
        "inspire pisciato\n",
        "\n",
        "influence only used as a name\n",
        "influences only used as a name, plural of influences\n",
        "inspiration only used as a name, similar to influence\n",
        "influenced used as verb\n",
        "inspired used like influenced\n",
        "\n",
        "X's can be changed with his\n",
        "Influence:\n",
        "X be an influence (of/on/for/to) Y \n",
        "X's influence (of/on/for/to) Y\n",
        "X be Y's influence\n",
        "\n",
        "influences:\n",
        "influences (include/of) X\n",
        "X be Y's influences\n",
        "X and X were influences of Y\n",
        "\n",
        "influencing:\n",
        "none\n",
        "\n",
        "influenced\n",
        "Y be influenced by X\n",
        "X have influenced Y\n",
        "Y's thinking was influenced by X\n",
        "X influenced Y\n",
        "\n",
        "X ispiratore Y ispirante\n",
        "inspired\n",
        "Y be influenced by X\n",
        "X have inspired Y\n",
        "Y had been inspired by X\n",
        "Y's thinking/work was inspired by X\n",
        "Y was inspired by X\n",
        "X inspired Y\n",
        "\n",
        "inspire\n",
        "X seemed/(verb) to inspire Y\n",
        "X's work inspire Y\n",
        "\n",
        "inspiration\n",
        "X became/was inspiration for Y\n",
        "X's work provided/was inspiration for Y\n",
        "X's work served as inspiration to Y\n",
        "Y took/drew inspiration from X\n",
        "X provided inspiration to Y\n",
        "\"\"\"\n",
        "\n",
        "print(len(counter_influence), \"influence\",\n",
        "      len(counter_influences), \"influences\",\n",
        "      len(counter_influencing), \"influencing\",\n",
        "      len(counter_influenced), \"influenced\",\n",
        "      len(counter_inspired), \"inspired\",\n",
        "      len(counter_inspire), \"inspire\",\n",
        "      len(counter_inspiration), \"inspiration\")\n",
        "for wl in counter_inspired:\n",
        "    print(' '.join(word for word in wl))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KW3Mf9UlSeKx",
        "colab_type": "text"
      },
      "source": [
        "# ***Processing Giuliano(Spacy Dependencies)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8rkKZ0aFSn-V",
        "colab_type": "code",
        "outputId": "27bfca1d-647a-4698-de0a-f96f75c2533a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "\"\"\"\n",
        "Input cella:\n",
        "jsonlist = \n",
        "[\n",
        "    {\n",
        "        \"philosopher\" = \"philosopher_name\",\n",
        "        \"pageid\" = id,\n",
        "        \"article\" = \n",
        "        [\n",
        "            \"frase contenente influence\",\n",
        "\n",
        "            \"frase contenente influence\", etc\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\n",
        "Output cella:\n",
        "output =\n",
        "[\n",
        "    {\n",
        "        \"philosopher\" = \"philosopher_name\",\n",
        "        \"pageid\" = id,\n",
        "        \"article\" = \n",
        "        [\n",
        "            [\n",
        "                \"frase contenente influence\",\n",
        "                [\n",
        "                    list of influencers\n",
        "                ],\n",
        "                [\n",
        "                    list of influenced\n",
        "                ]\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "#some prints and infos\n",
        "\n",
        "#pprint.pprint(jsonlist)\n",
        "print(len(jsonlist))\n",
        "jsonlist_no_empty = [i for i in jsonlist if len(i[\"article\"]) != 0]\n",
        "print(len(jsonlist_no_empty))\n",
        "print([[i[\"philosopher\"], len(i[\"article\"]), i[\"article\"]] for i in jsonlist_no_empty if i[\"philosopher\"] == \"Socrates\"])\n",
        "\"\"\"\n",
        "\"\"\"\n",
        "import re\n",
        "print(jsonlist_no_empty[20][\"article\"][0])\n",
        "tokens = [i for i in jsonlist_no_empty[20][\"article\"][0] if i.isupper() ]\n",
        "print(tokens)\n",
        "\"\"\"\n",
        "\n",
        "# for phil in jsonlist_no_empty:\n",
        "#     display_info(phil[\"article\"])\n",
        "\n",
        "\n",
        "import time\n",
        "start = time.time()\n",
        "\n",
        "for elem in jsonlist:\n",
        "    #divide in sentences the article\n",
        "    sent_list = nltk.sent_tokenize(elem[\"article\"])\n",
        "    \n",
        "    sent_list = [word_tokenize(i) for i in sent_list]\n",
        "\n",
        "    influence_list = []\n",
        "    influence_declinations = [\"influence\", \"influenced\", \"influences\", \"influencing\"]\n",
        "\n",
        "    for word_list in sent_list:\n",
        "        temp = [x for x in word_list if x in influence_declinations]\n",
        "        if len(temp) != 0:\n",
        "            influence_list.append(' '.join(word for word in word_list))\n",
        "\n",
        "    new_list = []\n",
        "    for sent in influence_list:\n",
        "        new_list.append(sent)\n",
        "        #displacy.render(sent, style=\"dep\", jupyter=True)\n",
        "    elem[\"article\"] = new_list\n",
        "\n",
        "print(time.time() - start)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "34.77304148674011\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j132TVHEKK3Q",
        "colab_type": "text"
      },
      "source": [
        "# ***Processing Mattia(Regex)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrBeoeMOKPs_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "#some prints and infos\n",
        "\n",
        "pprint.pprint(jsonlist)\n",
        "print(len(jsonlist))\n",
        "jsonlist_no_empty = [i for i in jsonlist if len(i[\"article\"]) != 0]\n",
        "print(len(jsonlist_no_empty))\n",
        "print([[i[\"philosopher\"], len(i[\"article\"]), i[\"article\"]] for i in jsonlist_no_empty if i[\"philosopher\"] == \"Socrates\"])\n",
        "\"\"\"\n",
        "import re\n",
        "#pprint.pprint(jsonlist)\n",
        "stringone = 'His philosophy is mainly influenced by such thinkers as Nietzsche , Epicurus , the Cynic and Cyrenaic schools , as well as French materialism .'\n",
        "relations = re.findall(r'[A-Z][a-z]+[\\s]', stringone)\n",
        "influence = re.findall(r'[iI]nfluenced[\\s]', stringone)\n",
        "dio = re.findall(r'[A-Z][a-z]+[\\s].*[iI]nfluenced[\\s].*[A-Za-z]+[\\s]', stringone)\n",
        "#print(re.split('[iI]nfluenced[\\s]by', stringone ,2)[1])\n",
        "left = re.split('[iI]nfluenced[\\s]by', stringone ,2)[0]\n",
        "#left = re.findall(r'[A-Z][a-z]+[\\s].*[iI]nfluenced[\\s]', stringone)\n",
        "right = re.split('[iI]nfluenced[\\s]by', stringone ,2)[1]\n",
        "#right = re.findall(r'[iI]nfluenced by[\\s].*', stringone)\n",
        "influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "\"\"\"\n",
        "print(stringone)\n",
        "print('Left: ' + str(left))\n",
        "print('Right: ' + str(right))\n",
        "print('Influencers: ' + str(influencers))\n",
        "print('Influenced: ' + str(influenced))\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "\n",
        "jsonlist_no_empty = [i for i in jsonlist if len(i[\"article\"]) != 0]\n",
        "\n",
        "for pippo in jsonlist_no_empty:\n",
        "  #print(len(pippo['article']))\n",
        "  #print(pippo.keys())\n",
        "  pippo['influencers'] = []\n",
        "  pippo['influenced'] = []\n",
        "  pippo['rich_article'] = {}\n",
        "  for i in range(len(pippo['article'])):\n",
        "    left = []\n",
        "    right = []\n",
        "    influencers = []\n",
        "    influenced = []\n",
        "\n",
        "    #print('Sentence: ' + pippo['article'][i])\n",
        "    try:\n",
        "      left = re.split('have[\\s].*[iI]nfluenced[\\s]', pippo['article'][i] ,2)[0]\n",
        "      right = re.split('have[\\s].*[iI]nfluenced[\\s]', pippo['article'][i] ,2)[1]\n",
        "      influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "      influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "    except:\n",
        "      try:\n",
        "        left = re.split('was[\\s].*[iI]nfluenced[\\s]', pippo['article'][i] ,2)[0]\n",
        "        right = re.split('was[\\s].*[iI]nfluenced[\\s]', pippo['article'][i] ,2)[1]\n",
        "        influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "        influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "      except:\n",
        "        try:\n",
        "          left = re.split('[iI]nfluenced[\\s]by[\\s]', pippo['article'][i] ,2)[0]\n",
        "          right = re.split('[iI]nfluenced[\\s]by[\\s]', pippo['article'][i] ,2)[1]\n",
        "          influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "          influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "        except:\n",
        "          try:\n",
        "            left = re.split('has[\\s][iI]nfluenced[\\s]', pippo['article'][i] ,2)[0]\n",
        "            right = re.split('has[\\s][iI]nfluenced[\\s]', pippo['article'][i] ,2)[1]\n",
        "            influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "            influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "          except:\n",
        "            try:\n",
        "              left = re.split('[iI]nfluenced[\\s]', pippo['article'][i] ,2)[0]\n",
        "              right = re.split('[iI]nfluenced[\\s]', pippo['article'][i] ,2)[1]\n",
        "              influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "              influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "            except:\n",
        "              try:\n",
        "                left = re.split('[iI]nfluence[\\s].*on[\\s]', pippo['article'][i] ,2)[0]\n",
        "                right = re.split('[iI]nfluence[\\s].*on[\\s]', pippo['article'][i] ,2)[1]\n",
        "                influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "                influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "              except:\n",
        "                try:\n",
        "                  left = re.split('[iI]nfluence[\\s].*of[\\s]', pippo['article'][i] ,2)[0]\n",
        "                  right = re.split('[iI]nfluence[\\s].*of[\\s]', pippo['article'][i] ,2)[1]\n",
        "                  influencers = re.findall(r'[A-Z][a-z]+[\\s]', str(right))\n",
        "                  influenced = re.findall(r'[A-Z][a-z]+[\\s]', str(left))\n",
        "                except:\n",
        "                  influencers = []\n",
        "                  influenced = []\n",
        "    pippo['rich_article'][i] = {}\n",
        "    pippo['rich_article'][i]['phrase'] = pippo['article'][i]\n",
        "    pippo['rich_article'][i]['influenced'] = influenced\n",
        "    pippo['rich_article'][i]['influencers'] = influencers\n",
        "\n",
        "    pippo['influencers'].append(influencers)\n",
        "    pippo['influenced'].append(influenced)\n",
        "    #print('Influencers: ' + str(influencers))\n",
        "    #print('Influenced: ' + str(influenced))\n",
        "\n",
        "for pippo in jsonlist_no_empty:\n",
        "  pippo['influenced'] = [item for sublist in pippo['influenced'] for item in sublist]\n",
        "  pippo['influencers'] = [item for sublist in pippo['influencers'] for item in sublist]\n",
        "  pprint.pprint(pippo)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fotsckLtKQHb",
        "colab_type": "text"
      },
      "source": [
        "# ***Processing Luigi(Regex)***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5f1PxUxKTto",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pprint\n",
        "# for phr in phrases_inspired:\n",
        "#   get_info([phr[0]])\n",
        "#   influenced, influencer = process(phr[0])\n",
        "#   print(\"______EVAL\")\n",
        "#   print(\"influenced = \",phr[1], \"influencers\", phr[2])\n",
        "#   print(\"influenced = \",influenced, \"influencers\", influencer)\n",
        "#   print(len([x for x in influenced if x in phr[1]]), \"on\", len(phr[1]))\n",
        "#   print(len([x for x in influencer if x in phr[2]]), \"on\", len(phr[2]))\n",
        "\"\"\"\n",
        "Input cella:\n",
        "jsonlist = \n",
        "[\n",
        "    {\n",
        "        \"philosopher\" = \"philosopher_name\",\n",
        "        \"pageid\" = id,\n",
        "        \"article\" = \n",
        "        [\n",
        "            \"frase contenente influence\",\n",
        "\n",
        "            \"frase contenente influence\", etc\n",
        "        ]\n",
        "    }\n",
        "]\n",
        "\"\"\"\n",
        "\n",
        "phrases_inspire=[\n",
        "                    [\"He seemed to inspire her\",[\"her\"],[\"He\"]],\n",
        "                    [\"These revolutionizing ideas of Wang Yangming would later inspire prominent Japanese thinkers like Motoori Norinaga\",[\"Mootori Norinaga\"],[\"Wang Yangming\"]],\n",
        "                    [\"John's work inspire Mark\",[\"John\"],[\"Mark\"]]\n",
        "                ]\n",
        "phrases_inspiration=[\n",
        "                        [\"John was inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"Rozanov is the main source of inspiration for Dmitry Galkovsky\",[\"Dmitry Galkovsky\"],[\"Rozanov\"]],\n",
        "                        [\"Jhon and Adam became inspiration for Mark\",[\"Mark\"],[\"John and Adam\"]],\n",
        "                        [\"Jhon's work provided inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"He got the inspiration for this text from Schleiermacher ’ s Über die Religion \",[\"He\"],[\"Schleiermacher\"]],\n",
        "                        [\"Jhon's work was inspiration for Mark\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"While Murdoch 's thought is an inspiration for Conradi\",[\"Conradi\"],[\"Murdoch\"]],\n",
        "                        [\"Jhon's work served as inspiration to Mark\",[\"Mark\"],[\"Jhon\"]],\n",
        "                        [\"Lucian 's True Story inspired Cyrano de Bergerac , whose writings later served as inspiration for Jules Verne \",[\"Cyrano de Bergerac\", \"Jules Verne\"],[\"Lucian\"]],\n",
        "                        [\"Mark took inspiration from John\",[\"Mark\"],[\"John\"]],\n",
        "                        [\"He also took inspiration from phenomenologist epistemology\",[\"He\"],[\"phenomenologist epistemology\"]],\n",
        "                        [\"Mark drew inspiration from John\", [\"Mark\"], [\"John\"]],\n",
        "                        [\"In particular , he drew inspiration from a Chinese Buddhist master named Tao-cho\",[\"he\"],[\"Tao-cho\"]],\n",
        "                        [\"Mark provided inspiration to John\",[\"John\"],[\"Mark\"]]\n",
        "                    ]\n",
        "phrases_inspired=[\n",
        "                    [\"He was inspired by him\",[\"He\"],[\"him\"]],\n",
        "                    [\"Mark have inspired Jhon\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"Jhon had been inspired by Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"In it , Petrarch claimed to have been inspired by Philip V of Macedon\",[\"Petrarch\"],[\"Philip V of Macedon\"]],\n",
        "                    [\"Jhon's thinking was inspired by Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [\"Newton 's work on infinite series was inspired by Simon Stevin 's decimals\",[\"Newton\"],[\"Simon Stevin\"]],\n",
        "                    [\"Jhon's work was inspired by Marks\",[\"John\"],[\"Marks\"]],\n",
        "                    [ \"Schiller was inspired by the play Julius of Tarent by Johann Anton Leisewitz .\",[\"Schiller\"],[\"Johann Anton Leisewitz\"]],\n",
        "                    [ \"Mark was inspired by Jhon\",[\"Mark\"],[\"John\"]],\n",
        "                    [\"As a youth , he was inspired by Mencius ’ proposition\",[\"he\"],[\"Mencius\"]],\n",
        "                    [\"Jhon inspired Mark\",[\"John\"],[\"Mark\"]],\n",
        "                    [ \"It also inspired him to take falsifiability as his criterion of demarcation between what is , and is not , genuinely scientific\",[\"him\"],[\"It\"]],\n",
        "                    [\"Jhon inspired Mark's work\",[\"Mark\"],[\"John\"]],\n",
        "                    [ \"Spinoza inspired the poet Shelley to write his essay\",[\"Shelley\"],[\"Spinoza\"]]\n",
        "                    \n",
        "                  ]\n",
        "\n",
        "\n",
        "output = [\n",
        "{\n",
        "    \"article\":[\n",
        "       \"== Influence == Zhuangzi has influenced thinking far beyond East Asia .\"\n",
        "    ],\n",
        "    \"influenced\":[\n",
        "       \"East \",\n",
        "       \"Asia \"\n",
        "    ],\n",
        "    \"influencers\":[\n",
        "       \"Influence \",\n",
        "       \"Zhuangzi \",\n",
        "       \"Rozanov\"\n",
        "    ],\n",
        "    \"pageid\":\"166152\",\n",
        "    \"philosopher\":\"Zhuang Zhou\",\n",
        "    \"rich_article\":[\n",
        "       {\n",
        "             \"influenced\":[\n",
        "                \"East \",\n",
        "                \"Asia \"\n",
        "             ],\n",
        "             \"influencers\":[\n",
        "                \"Influence \",\n",
        "                \"Zhuangzi \"\n",
        "             ],\n",
        "             \"phrase\":\"== Influence == Zhuangzi has influenced thinking far beyond East Asia .\"\n",
        "          }\n",
        "       \n",
        "    ]\n",
        " },\n",
        " {\n",
        "    \"article\":[\n",
        "       \"== Influence == Zhuangzi has influenced thinking far beyond East Asia .\"\n",
        "    ],\n",
        "    \"influenced\":[\n",
        "       \"East \",\n",
        "       \"Asia \"\n",
        "    ],\n",
        "    \"influencers\":[\n",
        "       \"Influence \",\n",
        "       \"Zhuangzi \"\n",
        "    ],\n",
        "    \"pageid\":\"166152\",\n",
        "    \"philosopher\":\"Zhuang Zhou\",\n",
        "    \"rich_article\":[\n",
        "       {\n",
        "          \"influenced\":[\n",
        "             \"East \",\n",
        "             \"Asia \"\n",
        "          ],\n",
        "          \"influencers\":[\n",
        "             \"Influence \",\n",
        "             \"Zhuangzi \",\n",
        "             \"Plato\",\n",
        "             \"William\",\n",
        "             \"Abbagnano\",\n",
        "             \"Ralph\",\n",
        "             \"Inge\",\n",
        "             \"Nicola\"\n",
        "          ],\n",
        "          \"phrase\":\"== Influence == Zhuangzi has influenced thinking far beyond East Asia .\"\n",
        "       },\n",
        "       {\n",
        "          \"influenced\":[\n",
        "             \"East \",\n",
        "             \"Asia \"\n",
        "          ],\n",
        "          \"influencers\":[\n",
        "             \"Influence \",\n",
        "             \"Zhuangzi \",\n",
        "             \"Plato\",\n",
        "             \"William\",\n",
        "             \"Ralph\",\n",
        "             \"Inge\"\n",
        "          ],\n",
        "          \"phrase\":\"== Influence == Zhuangzi has influenced thinking far beyond East Asia .\"\n",
        "       }\n",
        "    ]\n",
        " }\n",
        "                  \n",
        "]\n",
        "\n",
        "\n",
        "def myfunc(phil):\n",
        "    mtch_lst = []\n",
        "    for p in phil_name_list:\n",
        "        if p.startswith(phil) or phil in p:\n",
        "            mtch_lst.append(p)\n",
        "    return mtch_lst\n",
        "\n",
        "\n",
        "\n",
        "def founded_name(name,influencers):\n",
        "    splittato = name.split() \n",
        "    for part_of_name in splittato: #se trovi grazie al nome --> cancella il cognome ancora presente\n",
        "        try:\n",
        "            influencers.remove(part_of_name)\n",
        "        except:\n",
        "            continue\n",
        "    return name\n",
        "\n",
        "def aux_func(lst):\n",
        "    new_lst = []\n",
        "    for phil in lst:\n",
        "        if phil in phil_name_list:\n",
        "            new_lst.append(phil)\n",
        "            print(\"cioccato: \",phil)\n",
        "        else: #nome composto da piu stringhe ?\n",
        "            possible_names = myfunc(phil) \n",
        "            if len(possible_names) == 1: #cioccato\n",
        "                new_lst.append(founded_name(possible_names[0], lst))\n",
        "            else:\n",
        "                #cerca nomi nella lista per fare nome + cognome\n",
        "                for name in possible_names:\n",
        "                    splittato = name.split()\n",
        "                    try:\n",
        "                        splittato.remove(phil) #rimuovi da [William, Alston] William\n",
        "                    except:\n",
        "                        print(\"Exclude this phil=\", name)\n",
        "                    for word in splittato:\n",
        "                        if word in lst:\n",
        "                            founded_name(name,lst) \n",
        "                            new_lst.append(name)\n",
        "                            print(\"aggiunto: \", name)\n",
        "    return new_lst      \n",
        "\n",
        "\n",
        "def reconstruct_phil(output,phil_name_list):\n",
        "    for match in output:\n",
        "        art = match[\"rich_article\"]\n",
        "        for i in art:\n",
        "            new_lst_influenced = aux_func(i['influenced'])\n",
        "            new_lst_influencers = aux_func(i['influencers'])\n",
        "            i['influenced'] = new_lst_influenced\n",
        "            i['influencers'] = new_lst_influencers\n",
        "    return output\n",
        "    \n",
        "\n",
        "pprint.pprint(reconstruct_phil(output,phil_name_list))\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}